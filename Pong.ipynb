{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XDvssQd64Pf"
      },
      "source": [
        "!apt-get install -y xvfb python-opengl > /dev/null 2>&1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5esgX013vPe"
      },
      "source": [
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgOPeOI-FaIh"
      },
      "source": [
        "!pip install tensorboardX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGqXqJxoAsHG"
      },
      "source": [
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(400, 300))\n",
        "display.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hN2kqm6DAxO0"
      },
      "source": [
        "import matplotlib\n",
        "is_ipython = 'inline' in matplotlib.get_backend()\n",
        "if is_ipython: from IPython import display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BN_LQU_UBKOq"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.style.use(['dark_background'])\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPKYXrLeK3xM"
      },
      "source": [
        "import urllib.request\n",
        "urllib.request.urlretrieve('http://www.atarimania.com/roms/Roms.rar','Roms.rar')\n",
        "!pip install unrar\n",
        "!unrar x Roms.rar\n",
        "!mkdir rars\n",
        "!mv HC\\ ROMS.zip   rars\n",
        "!mv ROMS.zip  rars\n",
        "!python -m atari_py.import_roms rars"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yh3Xw0piILd"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot(steps_done, episode, t, total_rewards,total_reward):\n",
        "    plt.figure(2)\n",
        "    plt.clf()        \n",
        "    plt.title('Training...')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('total_reward')\n",
        "    plt.plot(total_rewards)\n",
        "\n",
        "    plt.pause(0.001)\n",
        "    print('Total steps: {} \\t Episode: {}/{} \\t Total reward: {}'\\\n",
        "          .format(steps_done, episode, t, total_reward))  \n",
        "    if is_ipython: display.clear_output(wait=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqG6CN_BDOm6"
      },
      "source": [
        "# import os\n",
        "# os.getcwd()\n",
        "# os.chdir(r'/content/drive/MyDrive/ANN_fall99/HW2/dataset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qi9JMkfXMitw"
      },
      "source": [
        "import copy\n",
        "from collections import namedtuple\n",
        "from itertools import count\n",
        "import math\n",
        "import random\n",
        "import numpy as np \n",
        "import time\n",
        "import pickle\n",
        "\n",
        "import gym\n",
        "\n",
        "from wrappers import *\n",
        "from memory import ReplayMemory\n",
        "from models import *\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "\n",
        "Transition = namedtuple('Transion', \n",
        "                        ('state', 'action', 'next_state', 'reward'))\n",
        "\n",
        "def select_action(state):\n",
        "    global steps_done\n",
        "    sample = random.random()\n",
        "    eps_threshold = EPS_END + (EPS_START - EPS_END)* \\\n",
        "        math.exp(-1. * steps_done / EPS_DECAY)\n",
        "    steps_done += 1\n",
        "    if sample > eps_threshold:\n",
        "        with torch.no_grad():\n",
        "            return policy_net(state.to('cuda')).max(1)[1].view(1,1)\n",
        "    else:\n",
        "        return torch.tensor([[random.randrange(4)]], device=device, dtype=torch.long)\n",
        "\n",
        "def get_state(obs):\n",
        "    state = np.array(obs)\n",
        "    state = state.transpose((2, 0, 1))\n",
        "    state = torch.from_numpy(state)\n",
        "    return state.unsqueeze(0)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjjHkioB7SUg"
      },
      "source": [
        "# DQN:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM2GGP07IhOm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "9e3cfa08-d12f-4d84-8f95-2b25d87272e2"
      },
      "source": [
        "def optimize_model():\n",
        "    if len(memory) < BATCH_SIZE:\n",
        "        return\n",
        "    transitions = memory.sample(BATCH_SIZE)\n",
        "    \"\"\"\n",
        "    zip(*transitions) unzips the transitions into\n",
        "    Transition(*) creates new named tuple\n",
        "    batch.state - tuple of all the states (each state is a tensor)\n",
        "    batch.next_state - tuple of all the next states (each state is a tensor)\n",
        "    batch.reward - tuple of all the rewards (each reward is a float)\n",
        "    batch.action - tuple of all the actions (each action is an int)    \n",
        "    \"\"\"\n",
        "    batch = Transition(*zip(*transitions))\n",
        "    \n",
        "    actions = tuple((map(lambda a: torch.tensor([[a]], device='cuda'), batch.action))) \n",
        "    rewards = tuple((map(lambda r: torch.tensor([r], device='cuda'), batch.reward))) \n",
        "\n",
        "    non_final_mask = torch.tensor(\n",
        "        tuple(map(lambda s: s is not None, batch.next_state)),\n",
        "        device=device, dtype=torch.uint8)\n",
        "    \n",
        "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
        "                                       if s is not None]).to('cuda')\n",
        "    \n",
        "\n",
        "    state_batch = torch.cat(batch.state).to('cuda')\n",
        "    action_batch = torch.cat(actions)\n",
        "    reward_batch = torch.cat(rewards)\n",
        "    \n",
        "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
        "    \n",
        "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
        "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
        "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
        "    \n",
        "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    for param in policy_net.parameters():\n",
        "        param.grad.data.clamp_(-1, 1)\n",
        "    optimizer.step()\n",
        "\n",
        "def train(env, n_episodes, render=False):\n",
        "    total_rewards = []\n",
        "    for episode in range(n_episodes):\n",
        "        obs = env.reset()\n",
        "        state = get_state(obs)\n",
        "        total_reward = 0.0\n",
        "        for t in count():\n",
        "            action = select_action(state)\n",
        "\n",
        "            if render:\n",
        "                env.render()\n",
        "\n",
        "            obs, reward, done, info = env.step(action)\n",
        "\n",
        "            total_reward += reward\n",
        "\n",
        "            if not done:\n",
        "                next_state = get_state(obs)\n",
        "            else:\n",
        "                next_state = None\n",
        "\n",
        "            reward = torch.tensor([reward], device=device)\n",
        "\n",
        "            memory.push(state, action.to('cpu'), next_state, reward.to('cpu'))\n",
        "            state = next_state\n",
        "\n",
        "            if steps_done > INITIAL_MEMORY:\n",
        "                optimize_model()\n",
        "\n",
        "                if steps_done % TARGET_UPDATE == 0:\n",
        "                    target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "        total_rewards.append(total_reward)\n",
        "        # if episode % 20 == 0:\n",
        "        plot(steps_done, episode, t, total_rewards,total_reward)      \n",
        "        # print('Total steps: {} \\t Episode: {}/{} \\t Total reward: {}'.format(steps_done, episode, t, total_reward))\n",
        "    env.close()\n",
        "    return\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # set device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # hyperparameters\n",
        "    BATCH_SIZE = 32\n",
        "    GAMMA = 0.99\n",
        "    EPS_START = 1\n",
        "    EPS_END = 0.02\n",
        "    EPS_DECAY = 1000000\n",
        "    TARGET_UPDATE = 1000\n",
        "    RENDER = False\n",
        "    lr = 1e-4\n",
        "    INITIAL_MEMORY = 10000\n",
        "    MEMORY_SIZE = 10 * INITIAL_MEMORY\n",
        "\n",
        "    # create networks\n",
        "    policy_net = DQN(n_actions=4).to(device)\n",
        "    target_net = DQN(n_actions=4).to(device)\n",
        "    target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "    # setup optimizer\n",
        "    optimizer = optim.Adam(policy_net.parameters(), lr=lr)\n",
        "\n",
        "    steps_done = 0\n",
        "\n",
        "    # create environment\n",
        "    env = gym.make(\"PongNoFrameskip-v4\")\n",
        "    env = make_env(env)\n",
        "\n",
        "    # initialize replay memory\n",
        "    memory = ReplayMemory(MEMORY_SIZE)\n",
        "    \n",
        "    # train model\n",
        "    train(env, 400)\n",
        "    # torch.save(policy_net, \"dqn_pong_model\")\n",
        "    # policy_net = torch.load(\"dqn_pong_model\")\n",
        "    # test(env, 1, policy_net, render=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "dark"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Total steps: 485369 \t Episode: 399/1491 \t Total reward: -17.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygLUXHnp7-K8"
      },
      "source": [
        "total_rewards"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuZTYkkEJcuL"
      },
      "source": [
        "# DDQN:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cosAEesgGnZD"
      },
      "source": [
        "t1 = time.time()\n",
        "def optimize_model():\n",
        "    if len(memory) < BATCH_SIZE:\n",
        "        return\n",
        "    transitions = memory.sample(BATCH_SIZE)\n",
        "    \"\"\"\n",
        "    zip(*transitions) unzips the transitions into\n",
        "    Transition(*) creates new named tuple\n",
        "    batch.state - tuple of all the states (each state is a tensor)\n",
        "    batch.next_state - tuple of all the next states (each state is a tensor)\n",
        "    batch.reward - tuple of all the rewards (each reward is a float)\n",
        "    batch.action - tuple of all the actions (each action is an int)    \n",
        "    \"\"\"\n",
        "    batch = Transition(*zip(*transitions))\n",
        "    \n",
        "    actions = tuple((map(lambda a: torch.tensor([[a]], device='cuda'), batch.action))) \n",
        "    rewards = tuple((map(lambda r: torch.tensor([r], device='cuda'), batch.reward))) \n",
        "\n",
        "    non_final_mask = torch.tensor(\n",
        "        tuple(map(lambda s: s is not None, batch.next_state)),\n",
        "        device=device, dtype=torch.uint8)\n",
        "    \n",
        "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
        "                                       if s is not None]).to('cuda')\n",
        "    \n",
        "\n",
        "    state_batch = torch.cat(batch.state).to('cuda')\n",
        "    action_batch = torch.cat(actions)\n",
        "    reward_batch = torch.cat(rewards)\n",
        "    \n",
        "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
        "    \n",
        "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
        "    ###\n",
        "    ###\n",
        "    am = policy_net(non_final_next_states).max(dim=1)[1] #argmaxes!\n",
        "    qs = target_net(non_final_next_states)\n",
        "    next_state_values[non_final_mask] = qs.gather(1, am.reshape(len(am),1)).reshape(len(qs)).detach()\n",
        "    ###\n",
        "    ###\n",
        "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
        "    \n",
        "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    for param in policy_net.parameters():\n",
        "        param.grad.data.clamp_(-1, 1)\n",
        "    optimizer.step()\n",
        "\n",
        "def train(env, n_episodes, render=False):\n",
        "    total_rewards = []\n",
        "    for episode in range(n_episodes):\n",
        "        if steps_done % TARGET_UPDATE == 0:\n",
        "          target_net.load_state_dict(policy_net.state_dict())\n",
        "        obs = env.reset()\n",
        "        state = get_state(obs)\n",
        "        total_reward = 0.0\n",
        "        for t in count():\n",
        "            action = select_action(state)\n",
        "\n",
        "            if render:\n",
        "                env.render()\n",
        "\n",
        "            obs, reward, done, info = env.step(action)\n",
        "\n",
        "            total_reward += reward\n",
        "\n",
        "            if not done:\n",
        "                next_state = get_state(obs)\n",
        "            else:\n",
        "                next_state = None\n",
        "\n",
        "            reward = torch.tensor([reward], device=device)\n",
        "\n",
        "            memory.push(state, action.to('cpu'), next_state, reward.to('cpu'))\n",
        "            state = next_state\n",
        "\n",
        "            if episode > INITIAL_MEMORY:\n",
        "                optimize_model()\n",
        "\n",
        "              # if steps_done % TARGET_UPDATE == 0:\n",
        "              #     target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "        total_rewards.append(total_reward)\n",
        "        # if episode % 20 == 0:\n",
        "        plot(steps_done, episode, t, total_rewards,total_reward)      \n",
        "        # print('Total steps: {} \\t Episode: {}/{} \\t Total reward: {}'.format(steps_done, episode, t, total_reward))\n",
        "    env.close()\n",
        "    return\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    BATCH_SIZE = 256\n",
        "    GAMMA = 0.99\n",
        "    EPS_START = 1\n",
        "    EPS_END = 0.01\n",
        "    EPS_DECAY = 1000000\n",
        "    TARGET_UPDATE = 10\n",
        "    RENDER = False\n",
        "    lr = 1e-3\n",
        "    INITIAL_MEMORY = 10000\n",
        "    MEMORY_SIZE = 50 * INITIAL_MEMORY\n",
        "\n",
        "    policy_net = DQN(n_actions=4).to(device)\n",
        "    target_net = DQN(n_actions=4).to(device)\n",
        "    target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "    optimizer = optim.Adam(policy_net.parameters(), lr=lr)\n",
        "\n",
        "    steps_done = 0\n",
        "\n",
        "    env = gym.make(\"PongNoFrameskip-v4\")\n",
        "    env = make_env(env)\n",
        "\n",
        "    memory = ReplayMemory(MEMORY_SIZE)\n",
        "    \n",
        "    train(env, 300)\n",
        "    t2 = time.time()\n",
        "    et_ddqn = t2-t1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaRBu-o38roz"
      },
      "source": [
        "print(et_ddqn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwAy22v7Agoq"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1xNNGWt7FnH"
      },
      "source": [
        "# TDQN:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeuFIXRLEm61"
      },
      "source": [
        "  def optimize_model():\n",
        "    if len(memory) < BATCH_SIZE:\n",
        "        return\n",
        "    transitions = memory.sample(BATCH_SIZE)\n",
        "\n",
        "    batch = Transition(*zip(*transitions))\n",
        "    \n",
        "    actions = tuple((map(lambda a: torch.tensor([[a]], device='cuda'), batch.action))) \n",
        "    rewards = tuple((map(lambda r: torch.tensor([r], device='cuda'), batch.reward))) \n",
        "\n",
        "    non_final_mask = torch.tensor(\n",
        "        tuple(map(lambda s: s is not None, batch.next_state)),\n",
        "        device=device, dtype=torch.uint8)\n",
        "    \n",
        "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
        "                                       if s is not None]).to('cuda')\n",
        "    \n",
        "\n",
        "    state_batch = torch.cat(batch.state).to('cuda')\n",
        "    action_batch = torch.cat(actions)\n",
        "    reward_batch = torch.cat(rewards)\n",
        "    \n",
        "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
        "    \n",
        "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
        "    ###\n",
        "    ###\n",
        "    am = target_net2(non_final_next_states).max(dim=1)[1] #argmaxes!\n",
        "    qs = target_net(non_final_next_states)\n",
        "    next_state_values[non_final_mask] = qs.gather(1, am.reshape(len(am),1)).reshape(len(qs)).detach()\n",
        "    ###\n",
        "    ###\n",
        "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
        "    \n",
        "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    for param in policy_net.parameters():\n",
        "        param.grad.data.clamp_(-1, 1)\n",
        "    optimizer.step()\n",
        "\n",
        "def train(env, n_episodes, render=False):\n",
        "    total_rewards = []\n",
        "    for episode in range(n_episodes):\n",
        "        obs = env.reset()\n",
        "        state = get_state(obs)\n",
        "        total_reward = 0.0\n",
        "        for t in count():\n",
        "            action = select_action(state)\n",
        "\n",
        "            if render:\n",
        "                env.render()\n",
        "\n",
        "            obs, reward, done, info = env.step(action)\n",
        "\n",
        "            total_reward += reward\n",
        "\n",
        "            if not done:\n",
        "                next_state = get_state(obs)\n",
        "            else:\n",
        "                next_state = None\n",
        "\n",
        "            reward = torch.tensor([reward], device=device)\n",
        "\n",
        "            memory.push(state, action.to('cpu'), next_state, reward.to('cpu'))\n",
        "            state = next_state\n",
        "\n",
        "            if steps_done > INITIAL_MEMORY:\n",
        "                optimize_model()\n",
        "\n",
        "                if steps_done % TARGET_UPDATE == 0:\n",
        "                    target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "                if steps_done % TARGET_UPDATE2 == 0:\n",
        "                    target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "        total_rewards.append(total_reward)\n",
        "        # if episode % 20 == 0:\n",
        "        plot(steps_done, episode, t, total_rewards,total_reward)      \n",
        "        # print('Total steps: {} \\t Episode: {}/{} \\t Total reward: {}'.format(steps_done, episode, t, total_reward))\n",
        "    env.close()\n",
        "    return\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    BATCH_SIZE = 32\n",
        "    GAMMA = 0.99\n",
        "    EPS_START = 1\n",
        "    EPS_END = 0.02\n",
        "    EPS_DECAY = 1000000\n",
        "    TARGET_UPDATE = 1000\n",
        "    TARGET_UPDATE2 = 500\n",
        "    RENDER = False\n",
        "    lr = 1e-4\n",
        "    INITIAL_MEMORY = 10000\n",
        "    MEMORY_SIZE = 10 * INITIAL_MEMORY\n",
        "\n",
        "    policy_net = DQN(n_actions=4).to(device)\n",
        "\n",
        "    target_net = DQN(n_actions=4).to(device)\n",
        "    target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "    target_net2 = DQN(n_actions=4).to(device)\n",
        "    target_net2.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "    optimizer = optim.Adam(policy_net.parameters(), lr=lr)\n",
        "\n",
        "    steps_done = 0\n",
        "\n",
        "    env = gym.make(\"PongNoFrameskip-v4\")\n",
        "    env = make_env(env)\n",
        "\n",
        "    memory = ReplayMemory(MEMORY_SIZE)\n",
        "    \n",
        "    train(env, 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYJ9ledn7IE3"
      },
      "source": [
        "# SDDQN:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWWbd1wV7LXT"
      },
      "source": [
        "  def optimize_model(policy,target1,target2,optimizer_):\n",
        "      if len(memory) < BATCH_SIZE:\n",
        "          return\n",
        "      transitions = memory.sample(BATCH_SIZE)\n",
        "\n",
        "      batch = Transition(*zip(*transitions))\n",
        "      \n",
        "      actions = tuple((map(lambda a: torch.tensor([[a]], device='cuda'), batch.action))) \n",
        "      rewards = tuple((map(lambda r: torch.tensor([r], device='cuda'), batch.reward))) \n",
        "\n",
        "      non_final_mask = torch.tensor(\n",
        "          tuple(map(lambda s: s is not None, batch.next_state)),\n",
        "          device=device, dtype=torch.uint8)\n",
        "      \n",
        "      non_final_next_states = torch.cat([s for s in batch.next_state\n",
        "                                        if s is not None]).to('cuda')\n",
        "      \n",
        "\n",
        "      state_batch = torch.cat(batch.state).to('cuda')\n",
        "      action_batch = torch.cat(actions)\n",
        "      reward_batch = torch.cat(rewards)\n",
        "      \n",
        "      state_action_values = policy(state_batch).gather(1, action_batch)\n",
        "      \n",
        "      next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
        "      ###\n",
        "      ###\n",
        "      am = target2(non_final_next_states).max(dim=1)[1] #argmaxes!\n",
        "      qs = target1(non_final_next_states)\n",
        "      next_state_values[non_final_mask] = qs.gather(1, am.reshape(len(am),1)).reshape(len(qs)).detach()\n",
        "      ###\n",
        "      ###\n",
        "      expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
        "      \n",
        "      loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
        "      \n",
        "      optimizer_.zero_grad()\n",
        "      loss.backward()\n",
        "      for param in policy.parameters():\n",
        "          param.grad.data.clamp_(-1, 1)\n",
        "      optimizer_.step()\n",
        "\n",
        "def train(env, n_episodes, render=False):\n",
        "    total_rewards = []\n",
        "    for episode in range(n_episodes):\n",
        "        obs = env.reset()\n",
        "        state = get_state(obs)\n",
        "        total_reward = 0.0\n",
        "        for t in count():\n",
        "            action = select_action(state)\n",
        "\n",
        "            if render:\n",
        "                env.render()\n",
        "\n",
        "            obs, reward, done, info = env.step(action)\n",
        "\n",
        "            total_reward += reward\n",
        "\n",
        "            if not done:\n",
        "                next_state = get_state(obs)\n",
        "            else:\n",
        "                next_state = None\n",
        "\n",
        "            reward = torch.tensor([reward], device=device)\n",
        "\n",
        "            memory.push(state, action.to('cpu'), next_state, reward.to('cpu'))\n",
        "            state = next_state\n",
        "\n",
        "            if steps_done > INITIAL_MEMORY:\n",
        "                optimize_model(policy_net,targe_net,target_net2,optimizer1)\n",
        "                optimize_model(policy_net2,targe_net2,target_net,optimizer2)\n",
        "\n",
        "                if steps_done % TARGET_UPDATE == 0:\n",
        "                    target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "                if steps_done % TARGET_UPDATE2 == 0:\n",
        "                    target_net2.load_state_dict(policy_net2.state_dict())\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "        total_rewards.append(total_reward)\n",
        "        # if episode % 20 == 0:\n",
        "        plot(steps_done, episode, t, total_rewards,total_reward)      \n",
        "        # print('Total steps: {} \\t Episode: {}/{} \\t Total reward: {}'.format(steps_done, episode, t, total_reward))\n",
        "    env.close()\n",
        "    return\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    BATCH_SIZE = 32\n",
        "    GAMMA = 0.99\n",
        "    EPS_START = 1\n",
        "    EPS_END = 0.02\n",
        "    EPS_DECAY = 1000000\n",
        "    TARGET_UPDATE = 1000\n",
        "    TARGET_UPDATE2 = 1000\n",
        "    RENDER = False\n",
        "    lr = 1e-4\n",
        "    INITIAL_MEMORY = 10000\n",
        "    MEMORY_SIZE = 10 * INITIAL_MEMORY\n",
        "\n",
        "    policy_net = DQN(n_actions=4).to(device)\n",
        "    policy_net2 = DQN(n_actions=4).to(device)\n",
        "\n",
        "    target_net = DQN(n_actions=4).to(device)\n",
        "    target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "    target_net2 = DQN(n_actions=4).to(device)\n",
        "    target_net2.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "    optimizer = optim.Adam(policy_net.parameters(), lr=lr)\n",
        "    optimizer2 = optim.Adam(policy_net2.parameters(), lr=lr)\n",
        "\n",
        "    steps_done = 0\n",
        "\n",
        "    env = gym.make(\"PongNoFrameskip-v4\")\n",
        "    env = make_env(env)\n",
        "\n",
        "    memory = ReplayMemory(MEMORY_SIZE)\n",
        "    \n",
        "    train(env, 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BMC9Rup7L7u"
      },
      "source": [
        "# FDDQN:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oc_-TIEB7Np8"
      },
      "source": [
        "  def optimize_model(policy,target1,target2,optimizer_):\n",
        "      if len(memory) < BATCH_SIZE:\n",
        "          return\n",
        "      transitions = memory.sample(BATCH_SIZE)\n",
        "\n",
        "      batch = Transition(*zip(*transitions))\n",
        "      \n",
        "      actions = tuple((map(lambda a: torch.tensor([[a]], device='cuda'), batch.action))) \n",
        "      rewards = tuple((map(lambda r: torch.tensor([r], device='cuda'), batch.reward))) \n",
        "\n",
        "      non_final_mask = torch.tensor(\n",
        "          tuple(map(lambda s: s is not None, batch.next_state)),\n",
        "          device=device, dtype=torch.uint8)\n",
        "      \n",
        "      non_final_next_states = torch.cat([s for s in batch.next_state\n",
        "                                        if s is not None]).to('cuda')\n",
        "      \n",
        "\n",
        "      state_batch = torch.cat(batch.state).to('cuda')\n",
        "      action_batch = torch.cat(actions)\n",
        "      reward_batch = torch.cat(rewards)\n",
        "      \n",
        "      state_action_values = policy(state_batch).gather(1, action_batch)\n",
        "      \n",
        "      next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
        "      ###\n",
        "      ###\n",
        "      am = target2(non_final_next_states).max(dim=1)[1] #argmaxes!\n",
        "      qs = target1(non_final_next_states)\n",
        "      next_state_values[non_final_mask] = qs.gather(1, am.reshape(len(am),1)).reshape(len(qs)).detach()\n",
        "      ###\n",
        "      ###\n",
        "      expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
        "      \n",
        "      loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
        "      \n",
        "      optimizer_.zero_grad()\n",
        "      loss.backward()\n",
        "      for param in policy.parameters():\n",
        "          param.grad.data.clamp_(-1, 1)\n",
        "      optimizer_.step()\n",
        "\n",
        "def train(env, n_episodes, render=False):\n",
        "    total_rewards = []\n",
        "    for episode in range(n_episodes):\n",
        "        obs = env.reset()\n",
        "        state = get_state(obs)\n",
        "        total_reward = 0.0\n",
        "        for t in count():\n",
        "            action = select_action(state)\n",
        "\n",
        "            if render:\n",
        "                env.render()\n",
        "\n",
        "            obs, reward, done, info = env.step(action)\n",
        "\n",
        "            total_reward += reward\n",
        "\n",
        "            if not done:\n",
        "                next_state = get_state(obs)\n",
        "            else:\n",
        "                next_state = None\n",
        "\n",
        "            reward = torch.tensor([reward], device=device)\n",
        "\n",
        "            memory.push(state, action.to('cpu'), next_state, reward.to('cpu'))\n",
        "            state = next_state\n",
        "\n",
        "            if steps_done > INITIAL_MEMORY:\n",
        "                optimize_model(policy_net,targe_net,target_net2,optimizer1)\n",
        "                optimize_model(policy_net2,targe_net2,target_net,optimizer2)\n",
        "\n",
        "                if steps_done % TARGET_UPDATE == 0:\n",
        "                    target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "                if steps_done % TARGET_UPDATE2 == 0:\n",
        "                    target_net2.load_state_dict(policy_net2.state_dict())\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "        total_rewards.append(total_reward)\n",
        "        # if episode % 20 == 0:\n",
        "        plot(steps_done, episode, t, total_rewards,total_reward)      \n",
        "        # print('Total steps: {} \\t Episode: {}/{} \\t Total reward: {}'.format(steps_done, episode, t, total_reward))\n",
        "    env.close()\n",
        "    return\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    BATCH_SIZE = 32\n",
        "    GAMMA = 0.99\n",
        "    EPS_START = 1\n",
        "    EPS_END = 0.02\n",
        "    EPS_DECAY = 1000000\n",
        "    TARGET_UPDATE = 1000\n",
        "    TARGET_UPDATE2 = 1000\n",
        "    RENDER = False\n",
        "    lr = 1e-4\n",
        "    INITIAL_MEMORY = 10000\n",
        "    MEMORY_SIZE = 10 * INITIAL_MEMORY\n",
        "\n",
        "    policy_net = DQN(n_actions=4).to(device)\n",
        "    policy_net2 = DQN(n_actions=4).to(device)\n",
        "\n",
        "    target_net = DQN(n_actions=4).to(device)\n",
        "    target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "    target_net2 = DQN(n_actions=4).to(device)\n",
        "    target_net2.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "    optimizer = optim.Adam(policy_net.parameters(), lr=lr)\n",
        "    optimizer2 = optim.Adam(policy_net2.parameters(), lr=lr)\n",
        "\n",
        "    steps_done = 0\n",
        "\n",
        "    env = gym.make(\"PongNoFrameskip-v4\")\n",
        "    env = make_env(env)\n",
        "\n",
        "    memory = ReplayMemory(MEMORY_SIZE)\n",
        "    \n",
        "    train(env, 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t99w__SSeatL"
      },
      "source": [
        "# Complementaries:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihCrf6WUe1gN"
      },
      "source": [
        "## save notebook:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn0lSd_OecfJ"
      },
      "source": [
        "# pip install dill\n",
        "\n",
        "# import dill\n",
        "# dill.dump_session('notebook_env.db')\n",
        "\n",
        "# dill.load_session('notebook_env.db')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xudbg663e950"
      },
      "source": [
        "## save variables:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hPsFat0e_vL"
      },
      "source": [
        "# import pickle\n",
        "\n",
        "# f = open('store.pkl', 'wb')\n",
        "# pickle.dump(obj, f)\n",
        "# f.close()\n",
        "\n",
        "# f = open('store.pkl', 'rb')\n",
        "# obj = pickle.load(f)\n",
        "# f.close()\n",
        "##############################\n",
        "# import pickle\n",
        "\n",
        "# # obj0, obj1, obj2 are created here...\n",
        "\n",
        "# # Saving the objects:\n",
        "# with open('objs.pkl', 'w') as f:  # Python 3: open(..., 'wb')\n",
        "#     pickle.dump([obj0, obj1, obj2], f)\n",
        "\n",
        "# # Getting back the objects:\n",
        "# with open('objs.pkl') as f:  # Python 3: open(..., 'rb')\n",
        "#     obj0, obj1, obj2 = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yQAtlmDfAtY"
      },
      "source": [
        "### Tesnsorboard:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYEBj4_jfAKr"
      },
      "source": [
        "# try:\n",
        "#   %tensorflow_version 2.x\n",
        "#   %load_ext tensorboard\n",
        "# except:\n",
        "#   pass\n",
        "\n",
        "####################33\n",
        "\n",
        "# %tensorboard --logdir 'logs'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_REM3jRjgh0T"
      },
      "source": [
        "## Tensorboard/Pytorch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z26mCKvcgmvz"
      },
      "source": [
        "# from torch.utils.tensorboard import SummaryWriter\n",
        "# tb = SummaryWriter(log_dir = '')\n",
        "# tb.add_scalar('Loss', total_loss, epoch)\n",
        "# tensorboard --logdir=runs\n",
        "# http://localhost:6006"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEDHqIl0gXEJ"
      },
      "source": [
        "## Execution Time:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1X31jDdgasn"
      },
      "source": [
        "# import time\n",
        "# t1 = time.time()\n",
        "# t2 = time.time()\n",
        "# print(t2-t1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}